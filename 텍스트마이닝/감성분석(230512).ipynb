{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 감성분석\n",
    "- ### 감성분석 : 텍스트에 나타난 주관적 요소를 분석하여 긍정,부정의 요소 및 그 정도를 판별하여 정량화하는 기법\n",
    "- ### 긍정과 부정을 판별할 뿐 아니라 긍정,부정의 대상이 되는 단어 또는 개체 를 추출하고 감성을 표현하는 이의 의도나 입장을 분석하는 것도 포함하는 개념"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 단어사전기반 분석 - 감성사전을 이용하여 각 단어의 감정 분류와 그 정도를 알 수 있어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트와 감성지수가 사전에 정의되어 있어야 함\n",
    "import glob\n",
    "from afinn import Afinn\n",
    "# imdb 데이터셋 5만건의 학습용, 검증용 데이터셋 긍정, 부정 리뷰로 라벨링되어 있음.\n",
    "# 긍정리뷰데이터 20번째 내용\n",
    "# glob.glob 특정한 패턴의 파일만 선택하는 함수\n",
    "pos_review = (glob.glob(\"../data/imdb/train/pos/*.txt\"))[20]\n",
    "f = open(pos_review, 'r')\n",
    "lines1 = f.readlines()[0] # 파일을 읽음\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 감성분석 객체\n",
    "afinn = Afinn()\n",
    "\n",
    "# 텍스트 전처리 후 감성점수 산출\n",
    "afinn.score(lines1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/imdb/train/pos\\\\0_9.txt',\n",
       " '../data/imdb/train/pos\\\\10000_8.txt',\n",
       " '../data/imdb/train/pos\\\\10001_10.txt',\n",
       " '../data/imdb/train/pos\\\\10002_7.txt',\n",
       " '../data/imdb/train/pos\\\\10003_8.txt',\n",
       " '../data/imdb/train/pos\\\\10004_8.txt',\n",
       " '../data/imdb/train/pos\\\\10005_7.txt',\n",
       " '../data/imdb/train/pos\\\\10006_7.txt',\n",
       " '../data/imdb/train/pos\\\\10007_7.txt',\n",
       " '../data/imdb/train/pos\\\\10008_7.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=list(glob.glob('../data/imdb/train/pos/*.txt')[:10])\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "2.0\n",
      "19.0\n",
      "3.0\n",
      "14.0\n",
      "8.0\n",
      "22.0\n",
      "28.0\n",
      "13.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "# 학습용 긍정리뷰 10개 파일만 테스트\n",
    "afinn=Afinn() # 감성분석 함수\n",
    "for i in files:\n",
    "    f=open(i) # 파일 오픈\n",
    "    lines1=f.readlines()[0] # 리스트의 첫번째 문자열\n",
    "    print(afinn.score(lines1)) # 감성점수\n",
    "    f.close()\n",
    "# 부정리뷰데이터 20번째 내용\n",
    "neg_review=(glob.glob(\"../data/imdb/train/neg/*.txt\"))[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(neg_review, 'r')\n",
    "lines2 = f.readlines()[0]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afinn.score(lines2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/imdb/train/neg\\\\0_3.txt',\n",
       " '../data/imdb/train/neg\\\\10000_4.txt',\n",
       " '../data/imdb/train/neg\\\\10001_4.txt',\n",
       " '../data/imdb/train/neg\\\\10002_1.txt',\n",
       " '../data/imdb/train/neg\\\\10003_1.txt',\n",
       " '../data/imdb/train/neg\\\\10004_3.txt',\n",
       " '../data/imdb/train/neg\\\\10005_3.txt',\n",
       " '../data/imdb/train/neg\\\\10006_4.txt',\n",
       " '../data/imdb/train/neg\\\\10007_1.txt',\n",
       " '../data/imdb/train/neg\\\\10008_2.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=list(glob.glob('../data/imdb/train/neg/*.txt')[:10])\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "-4.0\n",
      "9.0\n",
      "5.0\n",
      "-7.0\n",
      "1.0\n",
      "13.0\n",
      "4.0\n",
      "7.0\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# 학습용 부정리뷰 10개 파일만 테스트\n",
    "afinn=Afinn() # 감성분석 함수\n",
    "for i in files:\n",
    "    f=open(i) # 파일 오픈\n",
    "    lines1=f.readlines()[0] # 리스트의 첫번째 문자열\n",
    "    print(afinn.score(lines1)) # 감성점수\n",
    "    f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 기계학습으로 감성분석(시간이 매우 오래 걸림)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# 긍정 텍스트 로딩\n",
    "pos_review=(glob.glob(\"../data/imdb/train/pos/*.txt\")[:100])\n",
    "lines_pos=[]\n",
    "for i in pos_review:\n",
    "    try:\n",
    "        f = open(i, 'r')\n",
    "        temp = f.readlines()[0]\n",
    "        lines_pos.append(temp)\n",
    "        f.close()\n",
    "    except :\n",
    "        continue\n",
    "len(lines_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 부정 텍스트 로딩\n",
    "neg_review=(glob.glob(\"../data/imdb/train/neg/*.txt\")[:100])\n",
    "lines_neg=[]\n",
    "for i in neg_review:\n",
    "    try:\n",
    "        f = open(i, 'r')\n",
    "        temp = f.readlines()[0]\n",
    "        lines_neg.append(temp)\n",
    "        f.close()\n",
    "    except :\n",
    "        continue\n",
    "len(lines_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 긍정,부정 리뷰를 합침\n",
    "total_text=lines_pos+lines_neg\n",
    "len(total_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# 긍정,부정 클래스 라벨링\n",
    "x = np.array([\"pos\", \"neg\"])\n",
    "class_Index=np.repeat(x, [len(lines_pos), len(lines_neg)], axis=0)\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어들에 Tfidf 가중치를 부여한 후 문서-단어 매트릭스로 바꿈\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(stop_words=stop_words).fit(total_text)\n",
    "X_train_vectorized = vect.transform(total_text)\n",
    "X_train_vectorized.index = class_Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bromwell</th>\n",
       "      <th>high</th>\n",
       "      <th>cartoon</th>\n",
       "      <th>comedy</th>\n",
       "      <th>ran</th>\n",
       "      <th>time</th>\n",
       "      <th>programs</th>\n",
       "      <th>school</th>\n",
       "      <th>life</th>\n",
       "      <th>teachers</th>\n",
       "      <th>35</th>\n",
       "      <th>years</th>\n",
       "      <th>teaching</th>\n",
       "      <th>profession</th>\n",
       "      <th>lead</th>\n",
       "      <th>believe</th>\n",
       "      <th>satire</th>\n",
       "      <th>much</th>\n",
       "      <th>closer</th>\n",
       "      <th>reality</th>\n",
       "      <th>scramble</th>\n",
       "      <th>survive</th>\n",
       "      <th>financially</th>\n",
       "      <th>insightful</th>\n",
       "      <th>students</th>\n",
       "      <th>see</th>\n",
       "      <th>right</th>\n",
       "      <th>pathetic</th>\n",
       "      <th>pomp</th>\n",
       "      <th>pettiness</th>\n",
       "      <th>whole</th>\n",
       "      <th>situation</th>\n",
       "      <th>remind</th>\n",
       "      <th>schools</th>\n",
       "      <th>knew</th>\n",
       "      <th>saw</th>\n",
       "      <th>episode</th>\n",
       "      <th>student</th>\n",
       "      <th>repeatedly</th>\n",
       "      <th>tried</th>\n",
       "      <th>...</th>\n",
       "      <th>spell</th>\n",
       "      <th>romania</th>\n",
       "      <th>voodooism</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>clawing</th>\n",
       "      <th>covered</th>\n",
       "      <th>roadside</th>\n",
       "      <th>graves</th>\n",
       "      <th>prettier</th>\n",
       "      <th>glamor</th>\n",
       "      <th>generously</th>\n",
       "      <th>airbrushed</th>\n",
       "      <th>models</th>\n",
       "      <th>runway</th>\n",
       "      <th>borrows</th>\n",
       "      <th>lauded</th>\n",
       "      <th>countryman</th>\n",
       "      <th>injects</th>\n",
       "      <th>euro</th>\n",
       "      <th>techno</th>\n",
       "      <th>prehistoric</th>\n",
       "      <th>electronic</th>\n",
       "      <th>bumblebee</th>\n",
       "      <th>noise</th>\n",
       "      <th>ibiza</th>\n",
       "      <th>disco</th>\n",
       "      <th>shake</th>\n",
       "      <th>booty</th>\n",
       "      <th>function</th>\n",
       "      <th>er</th>\n",
       "      <th>zombified</th>\n",
       "      <th>auteur</th>\n",
       "      <th>ample</th>\n",
       "      <th>opportunities</th>\n",
       "      <th>golden</th>\n",
       "      <th>geist</th>\n",
       "      <th>uttered</th>\n",
       "      <th>downloading</th>\n",
       "      <th>midget</th>\n",
       "      <th>tricking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6514 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bromwell  high  cartoon  comedy  ...  uttered  downloading  midget  tricking\n",
       "0       0.0   0.0      0.0     0.0  ...      0.0          0.0     0.0       0.0\n",
       "1       0.0   0.0      0.0     0.0  ...      0.0          0.0     0.0       0.0\n",
       "2       0.0   0.0      0.0     0.0  ...      0.0          0.0     0.0       0.0\n",
       "3       0.0   0.0      0.0     0.0  ...      0.0          0.0     0.0       0.0\n",
       "4       0.0   0.0      0.0     0.0  ...      0.0          0.0     0.0       0.0\n",
       "\n",
       "[5 rows x 6514 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 데이터프레임으로 변환\n",
    "df = pd.DataFrame(X_train_vectorized.toarray(), columns=vect.vocabulary_.keys())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 0.10075971571307776\n",
      "189 0.10075971571307776\n",
      "212 0.09519036398460193\n",
      "583 0.06607233108770873\n",
      "770 0.4344371044102009\n",
      "813 0.10075971571307776\n",
      "889 0.09087043917100991\n",
      "1034 0.07745152705306162\n",
      "1062 0.09519036398460193\n",
      "1101 0.07093762711956966\n",
      "1916 0.09087043917100991\n",
      "2029 0.07093762711956966\n",
      "2121 0.06502562223418444\n",
      "2167 0.10860927610255022\n",
      "2202 0.10075971571307776\n",
      "2719 0.34800983331794577\n",
      "2895 0.10075971571307776\n",
      "3000 0.10860927610255022\n",
      "3005 0.10860927610255022\n",
      "3239 0.07949124320565701\n",
      "3310 0.09087043917100991\n",
      "3377 0.04921361834843082\n",
      "3397 0.06835253974870535\n",
      "3553 0.04749164856850098\n",
      "3818 0.040058435364654435\n",
      "4021 0.03193031768060858\n",
      "4168 0.09087043917100991\n",
      "4231 0.10860927610255022\n",
      "4277 0.10075971571307776\n",
      "4347 0.10860927610255022\n",
      "4469 0.10075971571307776\n",
      "4476 0.10860927610255022\n",
      "4606 0.10075971571307776\n",
      "4652 0.09519036398460193\n",
      "4664 0.10860927610255022\n",
      "4745 0.09087043917100991\n",
      "4760 0.10075971571307776\n",
      "4860 0.0630880667300972\n",
      "4944 0.10860927610255022\n",
      "4980 0.10860927610255022\n",
      "4989 0.06502562223418444\n",
      "5008 0.15121275870390602\n",
      "5010 0.10860927610255022\n",
      "5024 0.10860927610255022\n",
      "5064 0.040058435364654435\n",
      "5259 0.07745152705306162\n",
      "5554 0.19038072796920386\n",
      "5555 0.21721855220510045\n",
      "5665 0.09087043917100991\n",
      "5742 0.4344371044102009\n",
      "5744 0.10860927610255022\n",
      "5831 0.047084067241284604\n",
      "5881 0.0403410593324844\n",
      "6016 0.08177145186665363\n",
      "6339 0.09519036398460193\n",
      "6364 0.06403261493511332\n",
      "6482 0.054933627630757056\n"
     ]
    }
   ],
   "source": [
    "for idx,value in enumerate(X_train_vectorized[0].toarray()[0]):\n",
    "    if value>0:\n",
    "        print(idx, value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 로지스틱 회귀 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로지스틱 회귀 모형\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(random_state=10)\n",
    "logit.fit(X_train_vectorized, class_Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍정 리뷰들을 하나씩 불러와서 실험\n",
    "def pos_review(model):\n",
    "    count_all = 0\n",
    "    count = 0\n",
    "    num = 100\n",
    "    tests1 = []\n",
    "    for idx in range(0, num):\n",
    "        pos_review_test = (glob.glob(\"../data/imdb/test/pos/*.txt\"))[idx]\n",
    "        f = open(pos_review_test, 'r', encoding='utf-8')\n",
    "        tests1.append(f.readlines())\n",
    "        f.close()\n",
    "    for test in tests1:\n",
    "        pred = model.predict(vect.transform(test))\n",
    "        result = pred[0]\n",
    "        if result == \"pos\":\n",
    "            count += 1\n",
    "        count_all += 1\n",
    "    rate = count * 100 / count_all\n",
    "    print(f\"긍정정확도:{rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정정확도:66.0%\n",
      "부정정확도:82.0%\n"
     ]
    }
   ],
   "source": [
    "# 부정 리뷰들을 하나씩 불러와서 실험\n",
    "def neg_review(model):\n",
    "    count_all = 0\n",
    "    count = 0\n",
    "    num = 100\n",
    "    tests2 = []\n",
    "    for idx in range(0, num):\n",
    "        neg_review_test=(glob.glob(\"../data/imdb/test/neg/*.txt\"))[idx]\n",
    "        f = open(neg_review_test, 'r', encoding=\"utf-8\")\n",
    "        tests2.append(f.readlines())\n",
    "        f.close()\n",
    "    for test in tests2:\n",
    "        preds = model.predict(vect.transform(test))\n",
    "        result=preds[0]\n",
    "        if result == \"neg\":\n",
    "            count += 1\n",
    "        count_all += 1\n",
    "    rate= count * 100 / count_all\n",
    "    print(\"부정정확도:{0:.1f}%\".format(rate))\n",
    "pos_review(logit)\n",
    "neg_review(logit)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 의사결정나무 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정정확도:54.0%\n",
      "부정정확도:54.0%\n"
     ]
    }
   ],
   "source": [
    "# 의사결정나무 모형\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(random_state=10)\n",
    "tree.fit(X_train_vectorized, class_Index)\n",
    "pos_review(tree)\n",
    "neg_review(tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K최근접이웃 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정정확도:34.0%\n",
      "부정정확도:85.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train_vectorized, class_Index)\n",
    "pos_review(knn)\n",
    "neg_review(knn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 랜덤포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정정확도:46.0%\n",
      "부정정확도:70.0%\n"
     ]
    }
   ],
   "source": [
    "# 랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# 10개의 트리로 구성된 랜덤 포레스트\n",
    "forest = RandomForestClassifier(n_estimators=10,\n",
    "random_state=10)\n",
    "forest.fit(X_train_vectorized, class_Index)\n",
    "pos_review(forest)\n",
    "neg_review(forest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인공신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정정확도:63.0%\n",
      "부정정확도:76.0%\n"
     ]
    }
   ],
   "source": [
    "# 인공신경망\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state=10)\n",
    "mlp.fit(X_train_vectorized, class_Index)\n",
    "pos_review(mlp)\n",
    "neg_review(mlp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정정확도:63.0%\n",
      "부정정확도:86.0%\n"
     ]
    }
   ],
   "source": [
    "# SVM 모형\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(random_state=10)\n",
    "svm.fit(X_train_vectorized, class_Index)\n",
    "pos_review(svm)\n",
    "neg_review(svm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 나이브배이즈 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "train = [\n",
    "        ('I love this sandwich.', 'pos'),\n",
    "        ('This is an amazing place!', 'pos'),\n",
    "        ('I feel very good about these beers.', 'pos'),\n",
    "        ('This is my best work.', 'pos'),\n",
    "        ('What an awesome view', 'pos'),\n",
    "        ('I do not like this restaurant', 'neg'),\n",
    "        ('I am tired of this stuff.', 'neg'),\n",
    "        (\"I can't deal with this\", 'neg'),\n",
    "        ('He is my sworn enemy!', 'neg'),\n",
    "        ('My boss is horrible.', 'neg')\n",
    "    ]\n",
    "# 한글도 가능하다.\n",
    "test = [\n",
    "        ('The beer was good.', 'pos'),\n",
    "        ('I do not enjoy my job', 'neg'),\n",
    "        ('I am not feeling dandy today.', 'neg'),\n",
    "        ('I feel amazing!', 'pos'),\n",
    "        ('Gary is a friend of mine.', 'pos'),\n",
    "        (\"I can't believe I'm doing this.\", 'neg')\n",
    "    ]\n",
    "cl = NaiveBayesClassifier(train)\n",
    "print(cl.classify('Their burgers are amazing'))\n",
    "print(cl.classify(\"I don't like their pizza.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여러 문장을 종합하여 부정으로 분류\n",
    "blob = TextBlob(\"The beer was amazing. But the hangover was horrible. My boss was not happy.\", classifier=cl)\n",
    "blob.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The beer was amazing. ==> pos\n",
      "But the hangover was horrible. ==> neg\n",
      "My boss was not happy. ==> neg\n",
      "The beer was good. ==> pos\n",
      "I do not enjoy my job ==> neg\n",
      "I am not feeling dandy today. ==> neg\n",
      "I feel amazing! ==> pos\n",
      "Gary is a friend of mine. ==> neg\n",
      "I can't believe I'm doing this. ==> neg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개별 문장으로 분류\n",
    "for sentence in blob.sentences:\n",
    "    print(sentence, '==>', sentence.classify())\n",
    "\n",
    "# \"pos\", \"neg\", \"neg\"\n",
    "for row in test:\n",
    "    print(row[0], '==>', cl.classify(row[0]))\n",
    "\n",
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(this) = True              neg : pos    =      2.3 : 1.0\n",
      "          contains(this) = False             pos : neg    =      1.8 : 1.0\n",
      "          contains(This) = False             neg : pos    =      1.6 : 1.0\n",
      "            contains(an) = False             neg : pos    =      1.6 : 1.0\n",
      "             contains(I) = False             pos : neg    =      1.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.show_informative_features(5)\n",
    "# this가 포함된 경우 부정:긍정 = 2.3:1.0\n",
    "# this가 포함되지 않은 경우 긍정:부정 = 1.8:1.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
