{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 정수인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트를 숫자로 바꾸는 기법\n",
    "text = '''모처럼 전국에 비가 내리고 있습니다.\n",
    "        대부분 밤까지 계속되기 때문에 종일 우산이 필요하겠는데요.\n",
    "        비의 양도 많고 바람도 강하게 불기 때문에 작은 우산 말고 큰 우\n",
    "        산 챙기는 게 더 좋습니다.\n",
    "        특히 제주와 남해안에서 비바람이 강합니다.\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['모처럼 전국에 비가 내리고 있습니다.', '대부분 밤까지 계속되기 때문에 종일 우산이 필요하겠는데요.', '비의 양도 많고 바람도 강하게 불기 때문에 작은 우산 말고 큰 우\\n        산 챙기는 게 더 좋습니다.', '특히 제주와 남해안에서 비바람이 강합니다.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "# 문장 토큰화\n",
    "text = sent_tokenize(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['모처럼', '전국', '비'],\n",
       " ['대부분', '밤', '계속', '때문', '종일', '우산'],\n",
       " ['비', '양도', '바람', '불기', '때문', '우산', '산', '게', '더'],\n",
       " ['제주', '남해안', '비바람']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 명사만 추출하는 방법\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "text2 = []\n",
    "for txt in text:\n",
    "    t = okt.nouns(txt)\n",
    "    text2.append(t)\n",
    "\n",
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['모처럼', '전국', '비', '있습니다'], ['대부분', '밤', '계속', '때문', '종일', '우산', '필요하겠는데요'], ['비', '양도', '많고', '바람', '강하게', '불기', '때문', '작은', '우산', '산', '게', '더', '좋습니다'], ['제주', '남해안', '비바람', '강합니다']]\n"
     ]
    }
   ],
   "source": [
    "# 명사와 형용사를 추출하는 방법\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "text2 = []\n",
    "for txt in text:\n",
    "    morph = okt.pos(txt)\n",
    "    text2.append(morph)\n",
    "\n",
    "text3 = []\n",
    "for text in text2:\n",
    "    line=[]\n",
    "    for word, tag in text:\n",
    "        if tag in ['Noun','Adjective']:\n",
    "            line.append(word)\n",
    "    text3.append(line)\n",
    "    \n",
    "print(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['모처럼', '전국', '비', '있습니다'], ['대부분', '밤', '계속', '때문', '종일', '우산', '필요하겠는데요'], ['비', '양도', '많고', '바람', '강하게', '불기', '때문', '작은', '우산', '산', '좋습니다'], ['제주', '남해안', '비바람', '강합니다']]\n"
     ]
    }
   ],
   "source": [
    "vocab = {}\n",
    "sentences = []\n",
    "stop_words = ['더', '게']\n",
    "for txt in text3:\n",
    "    result = []\n",
    "    for word in txt:\n",
    "        if word not in stop_words: # 불용어가 아니면\n",
    "            result.append(word)\n",
    "            if word not in vocab: # 새로운 단어이면\n",
    "                vocab[word] = 0 # 출현횟수 0으로\n",
    "            vocab[word] += 1 # 출현횟수 증가\n",
    "    sentences.append(result)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'모처럼': 1, '전국': 1, '비': 2, '있습니다': 1, '대부분': 1, '밤': 1, '계속': 1, '때문': 2, '종일': 1, '우산': 2, '필요하겠는데요': 1, '양도': 1, '많고': 1, '바람': 1, '강하게': 1, '불기': 1, '작은': 1, '산': 1, '좋습니다': 1, '제주': 1, '남해안': 1, '비바람': 1, '강합니다': 1}\n"
     ]
    }
   ],
   "source": [
    "# 단어:출현빈도\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(vocab[\"우산\"]) # 단어의 빈도수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'비': 1, '때문': 2, '우산': 3}\n"
     ]
    }
   ],
   "source": [
    "# 단어에 일련번호 부여\n",
    "word_to_index = {}\n",
    "i=0\n",
    "for word in vocab :\n",
    "    if vocab[word] > 1 : # 빈도수가 1보다 큰 단어들만 추가\n",
    "        i=i+1\n",
    "        word_to_index[word] = i # 단어에 번호를 매김\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 4, 1, 4], [4, 4, 4, 2, 4, 3, 4], [1, 4, 4, 4, 4, 4, 2, 4, 3, 4, 4], [4, 4, 4, 4]]\n"
     ]
    }
   ],
   "source": [
    "# Out-Of-Vocabulary 단어 집합에 없는 단어\n",
    "# 출현빈도수가 낮은 단어들은 word_to_index에 없으므로\n",
    "# word_to_index에 OOV라는 단어를 추가하고 단어 집합에 없는 단어들은 OOV로 처리\n",
    "word_to_index['OOV'] = len(word_to_index) + 1\n",
    "encoded = []\n",
    "for s in sentences: # 문장들을 반복\n",
    "    temp = []\n",
    "    for w in s: # 문장의 단어들을 반복\n",
    "        try:\n",
    "            # 단어의 고유번호를 리스트에 추가\n",
    "            temp.append(word_to_index[w])\n",
    "        except:\n",
    "            # 존재하지 않는 단어는 OOV의 인덱스를 추가\n",
    "            temp.append(word_to_index['OOV'])\n",
    "    encoded.append(temp)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['모처럼' '전국' '비' '있습니다' '대부분' '밤' '계속' '때문' '종일' '우산' '필요하겠는데요' '비' '양도'\n",
      " '많고' '바람' '강하게' '불기' '때문' '작은' '우산' '산' '좋습니다' '제주' '남해안' '비바람' '강합니다']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#2차원 데이터를 1차원으로 바꾸고\n",
    "words = np.hstack(sentences)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'비': 2, '때문': 2, '우산': 2, '모처럼': 1, '전국': 1, '있습니다': 1, '대부분': 1, '밤': 1, '계속': 1, '종일': 1, '필요하겠는데요': 1, '양도': 1, '많고': 1, '바람': 1, '강하게': 1, '불기': 1, '작은': 1, '산': 1, '좋습니다': 1, '제주': 1, '남해안': 1, '비바람': 1, '강합니다': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "vocab = Counter(words) # 단어의 출현빈도를 쉽게 계산하는 클래스\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(vocab[\"우산\"]) # 단어의 빈도수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('비', 2), ('때문', 2), ('우산', 2), ('모처럼', 1), ('전국', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 5\n",
    "# 출현빈도가 높은 상위 5개의 단어\n",
    "vocab = vocab.most_common(vocab_size)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'비': 1, '때문': 2, '우산': 3, '모처럼': 4, '전국': 5}\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {}\n",
    "i = 0\n",
    "for (word, frequency) in vocab :\n",
    "    i = i+1\n",
    "    word_to_index[word] = i\n",
    "print(word_to_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 원핫인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '학교', '에', '간다', '나', '는', '집', '에', '간다']\n"
     ]
    }
   ],
   "source": [
    "# 정수인코딩의 단점 : 단어의 순서가 없음\n",
    "# 원핫인코딩 : 단어의 순서에 맞게 배열\n",
    "from konlpy.tag import Okt\n",
    "okt=Okt()\n",
    "# 토근화(형태소 분석)\n",
    "token=okt.morphs(\"나는 학교에 간다 나는 집에 간다\")\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나': 0, '는': 1, '학교': 2, '에': 3, '간다': 4, '집': 5}\n"
     ]
    }
   ],
   "source": [
    "# 중복된 단어는 제외하고 단어를 key로 고유한 숫자 인덱스 부여\n",
    "word2index={}\n",
    "for idx,voca in enumerate(token):\n",
    "    if voca not in word2index.keys():\n",
    "        word2index[voca]=len(word2index)\n",
    "print(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['나', '는', '학교', '에', '간다', '집'])\n",
      "나 [1, 0, 0, 0, 0, 0]\n",
      "는 [0, 1, 0, 0, 0, 0]\n",
      "학교 [0, 0, 1, 0, 0, 0]\n",
      "에 [0, 0, 0, 1, 0, 0]\n",
      "간다 [0, 0, 0, 0, 1, 0]\n",
      "집 [0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# 원핫인코딩 함수\n",
    "def one_hot_encoding(word, word2index):\n",
    "    # 전체 단어 갯수만큼 0으로 채운 리스트\n",
    "    one_hot_vector = [0]*(len(word2index))\n",
    "    # 해당하는 단어의 인덱스를 찾아\n",
    "    index = word2index[word]\n",
    "    # 1로 설정(나머지는 0)\n",
    "    one_hot_vector[index] = 1\n",
    "    return one_hot_vector\n",
    "\n",
    "key_list = word2index.keys()\n",
    "print(key_list)\n",
    "for key in key_list:\n",
    "    print(key, one_hot_encoding(key,word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 1, '간다': 2, '학교에': 3, '집에': 4}\n"
     ]
    }
   ],
   "source": [
    "# 케라스에서 지원하는 원핫인코딩 함수\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "text = \"나는 학교에 간다 나는 집에 간다\"\n",
    "t = Tokenizer()\n",
    "\n",
    "# 각 단어에 대한 정수 인코딩\n",
    "t.fit_on_texts([text])\n",
    "print(t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "# 각 단어에 매핑된 숫자로 변환된 리스트\n",
    "sub_text = \"나는 집에 간다\"\n",
    "encoded = t.texts_to_sequences([sub_text])[0]\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 원핫인코딩\n",
    "one_hot = to_categorical(encoded)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫인코딩의 단점:\n",
    "# 단어 갯수가 많아지면 변수의 갯수가 많아지게 됨\n",
    "# 메모리 활용의 비효율성: 변수가 100개 있다면 99개의 0과 1개의 0으로 구성됨\n",
    "# 비슷한 단어들의 유사성을 표현하기 어려움\n",
    "# 강아지 [0,1,1]와 개 [1,0,0] 이라면 비슷한 단어이지만 유사성을 찾기 어려움\n",
    "# 유사성을 찾기 위한 방법으로 LSA, RNN, Word2Vec 등의 방법이 있음"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. BOW(Bag Of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'비': 0, '가': 1, '오니': 2, '마음': 3, '이': 4, '차분해지네요': 5, '요즘': 6, '너무': 7, '더웠어요': 8, '기쁘네요': 9}\n"
     ]
    }
   ],
   "source": [
    "# Bag Of Words(BOW) : 단어의 등장 순서를 고려하지 않은 빈도수 기반의 텍스트 데이터의 수치화 방법\n",
    "# 가방에 단어들을 넣으면 순서가 중요하지 않음\n",
    "# 각 단어에 고유한 인덱스를 부여하고\n",
    "# 각 인덱스의 위치에 단어의 출현 횟수를 저장\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "import re\n",
    "okt = Okt()\n",
    "token = re.sub(\"[.!#~]\", \"\", '비가 오니 마음이 차분해지네요. 요즘 너무 더웠어요. 비가 오니 마음이 기쁘네요.')\n",
    "\n",
    "# 형태소 분석\n",
    "token = okt.morphs(token)\n",
    "word2index = {} # 단어 사전(단어와 숫자 인덱스)\n",
    "bow = [] # 단어 가방(단어와 출현 횟수)\n",
    "for voca in token:\n",
    "    # 사전에 없는 단어 추가\n",
    "    if voca not in word2index.keys():\n",
    "        word2index[voca] = len(word2index)\n",
    "        # 단어의 인덱스와 출현횟수(기본값 = 1)\n",
    "        bow.insert(len(word2index)-1, 1)\n",
    "    else:\n",
    "        # 재등장하는 단어의 인덱스\n",
    "        index = word2index.get(voca)\n",
    "        # 단어의 카운트 증가\n",
    "        bow[index] = bow[index] + 1\n",
    "\n",
    "print(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#단어의 출현 횟수\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'모처럼': 1, '전국에': 4, '비가': 2, '내리고': 0, '있습니다': 3}\n",
      "[[0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# 문서 집합에서 단어 토큰을 생성하고 각 단어의 수를 세어 BOW 인코딩한 벡터를 만드는 클래스\n",
    "corpus=['모처럼 전국에 비가 내리고 있습니다.']\n",
    "line=['전국에 비가']\n",
    "vector = CountVectorizer()\n",
    "vector.fit(corpus)\n",
    "print(vector.vocabulary_)\n",
    "print(vector.transform(line).toarray()) # 단어 위치에 1 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "{'모처럼': 7, '전국에': 18, '비가': 11, '내리고': 2, '있습니다': 16, '대부분': 3, '밤까지': 9, '계속되기': 1, '때문에': 4, '종일': 19, '우산이': 15, '필요하겠는데요': 22, '비의': 12, '양도': 13, '많고': 5, '바람도': 8, '강하게': 0, '불기': 10, '작은': 17, '우산': 14, '말고': 6, '챙기는': 21, '좋습니다': 20}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = ['''모처럼 전국에 비가 내리고 있습니다.\n",
    "            대부분 밤까지 계속되기 때문에 종일 우산이 필요하겠는데요.\n",
    "            비의 양도 많고 바람도 강하게 불기 때문에 작은 우산 말고 큰 우\n",
    "            산 챙기는 게 더 좋습니다. ''']\n",
    "# 문서 집합에서 단어 토큰을 생성하고 각 단어의 수를 세어 BOW 인코딩한 벡터를 만드는 클래스\n",
    "vector = CountVectorizer()\n",
    "# 코퍼스로부터 각 단어의 빈도수 계산\n",
    "# 단어들의 출현 횟수\n",
    "print(vector.fit_transform(corpus).toarray())\n",
    "# 만들어진 단어와 인덱스\n",
    "print(vector.vocabulary_) # 단어사전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['정부 코로나 방역 조치 대부분 해제 사실 상의 엔데믹 풍토병 감염병 선언 국내 첫 코로나 확 진자 발생 개월 만이 코로나 중앙 재난 안전 대책 본부 중 대본 윤석열 대통령 주재 회의 격리 의무 해제 내용 방역 완화 조치 발표 코로나 확산 감염병 위기 경보 단계 심각 경계 로 하향 조정 감염병 등급 급 급 내용 것 이 조치 병 의원 약국 감염 취약 시설 등 마스크 착용 의무 가능성 지난 첫 확 진자 발생 뒤 개월 대부분 방역 규제 것 정부 재난 관리 범 정부 차원 중 대본 것 보건복지부 중앙 사고 수습 본부 중수 질병 관리 청 중앙 방역 대책 본부 방 대본 총괄 변결 전망 다만 병원 등 감염 취약 시설 격리 의무 의견 격리 의무 확진 이후 격리 권고 방안 거론 본격 시행 달 말 다음 달 초 가능성 격리 의무 해제 고시 개정 행정 예고 규제 심사 등 절차 소요']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 공백 단위로 나누어지므로 한국어의 경우 정확도가 떨어짐(비슷한 단어들도 별도로 집계됨)\n",
    "f = open('../data/text/news1.txt')\n",
    "corpus = f.read()\n",
    "txt = okt.nouns(corpus)\n",
    "txt2 = [' '.join(txt)]\n",
    "txt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAYBElEQVR4nO3da4yU5fnA4XsFGRQXqijClqNaRTlYC1bX8ldbrQ3dmhrbRo0HrPWDBi2UHmCxCWKkyyejje22WkM1ajFGsbSoFVuB2gYVwlZEgxhAt56INe4ixjHC8//QMOm6oM7yjDDDdSVv0nnmnZnnzmL5ZXaGty6llAIAIIMD9vYGAIDaISwAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACCb3p/1C+7YsSNee+21qK+vj7q6us/65QGAHkgpxdatW6OhoSEOOGD370t85mHx2muvxbBhwz7rlwUAMmhvb4+hQ4fu9v7PPCzq6+sj4r8b69+//2f98gBAD3R2dsawYcNKf4/vzmceFjt//dG/f39hAQBV5pM+xuDDmwBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIpqywuP7666Ourq7LMXjw4ErtDQCoMmVfK2TMmDHx+OOPl2736tUr64YAgOpVdlj07t3buxQAwC6V/RmLDRs2RENDQ4waNSouvPDC2Lhx48eeXywWo7Ozs8sBANSmst6xOOWUU+Kuu+6KY489Nt5888248cYb47TTTot169bFwIEDd/mYlpaWmDt3bpbNfpKRs5Z0W9s8v6nb+ub5TZ/JfgBgf1PWOxaTJ0+O73znOzFu3Lg4++yzY8mS//6Ffeedd+72Mc3NzdHR0VE62tvb92zHAMA+q+zPWPyvfv36xbhx42LDhg27PadQKEShUNiTlwEAqsQe/TsWxWIxXnjhhRgyZEiu/QAAVayssPjJT34Sy5cvj02bNsVTTz0V3/3ud6OzszOmTJlSqf0BAFWkrF+F/Pvf/46LLroo3nrrrTjiiCPi1FNPjZUrV8aIESMqtT8AoIqUFRYLFy6s1D4AgBrgWiEAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIJs9CouWlpaoq6uL6dOnZ9oOAFDNehwWzzzzTNx2220xfvz4nPsBAKpYj8Li3XffjYsvvjhuv/32OPTQQ3PvCQCoUj0Ki6lTp0ZTU1OcffbZn3husViMzs7OLgcAUJt6l/uAhQsXxurVq2PVqlWf6vyWlpaYO3du2Rv7LIyctaTL7c3zm7qt7VwHAD5ZWe9YtLe3x7Rp0+Kee+6Jvn37fqrHNDc3R0dHR+lob2/v0UYBgH1fWe9YrF69OrZs2RITJkworW3fvj1WrFgRt956axSLxejVq1eXxxQKhSgUCnl2CwDs08oKi7POOivWrl3bZe373/9+jB49OmbOnNktKgCA/UtZYVFfXx9jx47tstavX78YOHBgt3UAYP/jX94EALIp+1shH7Vs2bIM2wAAaoF3LACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIpKyxaW1tj/Pjx0b9//+jfv380NjbGI488Uqm9AQBVpqywGDp0aMyfPz9WrVoVq1atiq997Wvx7W9/O9atW1ep/QEAVaR3OSefe+65XW7PmzcvWltbY+XKlTFmzJisGwMAqk9ZYfG/tm/fHvfff39s27YtGhsbd3tesViMYrFYut3Z2dnTlwQA9nFlh8XatWujsbEx3n///TjkkENi0aJFccIJJ+z2/JaWlpg7d+4ebXJfMHLWkm5rm+c3dVvf1Vq565vnN+3yNT/uOQBgX1D2t0KOO+64aGtri5UrV8bVV18dU6ZMieeff3635zc3N0dHR0fpaG9v36MNAwD7rrLfsejTp08cc8wxERExceLEeOaZZ+KWW26J3/72t7s8v1AoRKFQ2LNdAgBVYY//HYuUUpfPUAAA+6+y3rGYPXt2TJ48OYYNGxZbt26NhQsXxrJly+LRRx+t1P4AgCpSVli8+eabcemll8brr78eAwYMiPHjx8ejjz4aX//61yu1PwCgipQVFnfccUel9gEA1ADXCgEAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMimrLBoaWmJk08+Oerr62PQoEFx3nnnxfr16yu1NwCgypQVFsuXL4+pU6fGypUrY+nSpfHhhx/GOeecE9u2bavU/gCAKtK7nJMfffTRLrcXLFgQgwYNitWrV8fpp5+edWMAQPUpKyw+qqOjIyIiDjvssN2eUywWo1gslm53dnbuyUsCAPuwHodFSilmzJgRkyZNirFjx+72vJaWlpg7d25PX4ZPaeSsJd3WNs9v6ra+eX7TLs/f1bnlrud6jkruD4DK6vG3Qq655pp49tln4w9/+MPHntfc3BwdHR2lo729vacvCQDs43r0jsW1114bixcvjhUrVsTQoUM/9txCoRCFQqFHmwMAqktZYZFSimuvvTYWLVoUy5Yti1GjRlVqXwBAFSorLKZOnRr33ntv/PGPf4z6+vp44403IiJiwIABcdBBB1VkgwBA9SjrMxatra3R0dERZ555ZgwZMqR03HfffZXaHwBQRcr+VQgAwO64VggAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyKbssFixYkWce+650dDQEHV1dfHQQw9VYFsAQDUqOyy2bdsWJ554Ytx6662V2A8AUMV6l/uAyZMnx+TJkyuxFwCgypUdFuUqFotRLBZLtzs7Oyv9kgDAXlLxsGhpaYm5c+dW+mXgUxk5a0m3tc3zmz71+ub5Tbt8nnKeY289t/3tu89tf/vuc1fr/vamin8rpLm5OTo6OkpHe3t7pV8SANhLKv6ORaFQiEKhUOmXAQD2Af4dCwAgm7LfsXj33XfjpZdeKt3etGlTtLW1xWGHHRbDhw/PujkAoLqUHRarVq2Kr371q6XbM2bMiIiIKVOmxO9///tsGwMAqk/ZYXHmmWdGSqkSewEAqpzPWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGTTo7D49a9/HaNGjYq+ffvGhAkT4u9//3vufQEAVajssLjvvvti+vTpcd1118WaNWvi//7v/2Ly5MnxyiuvVGJ/AEAVKTssbrrppvjBD34QV155ZRx//PFx8803x7Bhw6K1tbUS+wMAqkjvck7+4IMPYvXq1TFr1qwu6+ecc07885//3OVjisViFIvF0u2Ojo6IiOjs7Cx3r59oR/G9bmudnZ3d1ne+9q7WP+1zfNxz53iOSu6vks9tf/vuc9vfvvvc9rfvPne17q8Sdj5vSunjT0xlePXVV1NEpH/84x9d1ufNm5eOPfbYXT5mzpw5KSIcDofD4XDUwNHe3v6xrVDWOxY71dXVdbmdUuq2tlNzc3PMmDGjdHvHjh3x9ttvx8CBA3f7mD3R2dkZw4YNi/b29ujfv3/2599X7A9zmrE27A8zRuwfc5qxNvR0xpRSbN26NRoaGj72vLLC4vDDD49evXrFG2+80WV9y5YtceSRR+7yMYVCIQqFQpe1z33uc+W8bI/079+/Zv9Q/K/9YU4z1ob9YcaI/WNOM9aGnsw4YMCATzynrA9v9unTJyZMmBBLly7tsr506dI47bTTytocAFB7yv5VyIwZM+LSSy+NiRMnRmNjY9x2223xyiuvxFVXXVWJ/QEAVaTssLjgggviP//5T9xwww3x+uuvx9ixY+Phhx+OESNGVGJ/ZSsUCjFnzpxuv36pNfvDnGasDfvDjBH7x5xmrA2VnrEufeL3RgAAPh3XCgEAshEWAEA2wgIAyEZYAADZ1FxY1NIl3VesWBHnnntuNDQ0RF1dXTz00ENd7k8pxfXXXx8NDQ1x0EEHxZlnnhnr1q3bO5vtoZaWljj55JOjvr4+Bg0aFOedd16sX7++yznVPmdra2uMHz++9I/RNDY2xiOPPFK6v9rn25WWlpaoq6uL6dOnl9ZqYc7rr78+6urquhyDBw8u3V8LM0ZEvPrqq3HJJZfEwIED4+CDD44vfvGLsXr16tL91T7nyJEju/0c6+rqYurUqRFR/fNFRHz44Yfx85//PEaNGhUHHXRQHHXUUXHDDTfEjh07SudUbM5yrhWyr1u4cGE68MAD0+23356ef/75NG3atNSvX7/08ssv7+2t9cjDDz+crrvuuvTAAw+kiEiLFi3qcv/8+fNTfX19euCBB9LatWvTBRdckIYMGZI6Ozv3zoZ74Bvf+EZasGBBeu6551JbW1tqampKw4cPT++++27pnGqfc/HixWnJkiVp/fr1af369Wn27NnpwAMPTM8991xKqfrn+6inn346jRw5Mo0fPz5NmzattF4Lc86ZMyeNGTMmvf7666Vjy5YtpftrYca33347jRgxIl1++eXpqaeeSps2bUqPP/54eumll0rnVPucW7Zs6fIzXLp0aYqI9MQTT6SUqn++lFK68cYb08CBA9Of//zntGnTpnT//fenQw45JN18882lcyo1Z02FxZe//OV01VVXdVkbPXp0mjVr1l7aUT4fDYsdO3akwYMHp/nz55fW3n///TRgwID0m9/8Zi/sMI8tW7akiEjLly9PKdXunIceemj63e9+V3Pzbd26NX3hC19IS5cuTWeccUYpLGplzjlz5qQTTzxxl/fVyowzZ85MkyZN2u39tTLn/5o2bVo6+uij044dO2pmvqampnTFFVd0WTv//PPTJZdcklKq7M+xZn4VsvOS7uecc06X9Y+7pHs127RpU7zxxhtd5i0UCnHGGWdU9bwdHR0REXHYYYdFRO3NuX379li4cGFs27YtGhsba26+qVOnRlNTU5x99tld1mtpzg0bNkRDQ0OMGjUqLrzwwti4cWNE1M6MixcvjokTJ8b3vve9GDRoUJx00klx++23l+6vlTl3+uCDD+Luu++OK664Iurq6mpmvkmTJsVf//rXePHFFyMi4l//+lc8+eST8c1vfjMiKvtz7NHVTfdFb731Vmzfvr3bxdCOPPLIbhdNqwU7Z9rVvC+//PLe2NIeSynFjBkzYtKkSTF27NiIqJ05165dG42NjfH+++/HIYccEosWLYoTTjih9B9wtc8XEbFw4cJYvXp1rFq1qtt9tfJzPOWUU+Kuu+6KY489Nt5888248cYb47TTTot169bVzIwbN26M1tbWmDFjRsyePTuefvrp+OEPfxiFQiEuu+yymplzp4ceeijeeeeduPzyyyOidv6szpw5Mzo6OmL06NHRq1ev2L59e8ybNy8uuuiiiKjsnDUTFjuVc0n3WlBL815zzTXx7LPPxpNPPtntvmqf87jjjou2trZ455134oEHHogpU6bE8uXLS/dX+3zt7e0xbdq0eOyxx6Jv3767Pa/a55w8eXLpf48bNy4aGxvj6KOPjjvvvDNOPfXUiKj+GXfs2BETJ06MX/ziFxERcdJJJ8W6deuitbU1LrvsstJ51T7nTnfccUdMnjy526XAq32+++67L+6+++649957Y8yYMdHW1hbTp0+PhoaGmDJlSum8SsxZM78K6ckl3avZzk+i18q81157bSxevDieeOKJGDp0aGm9Vubs06dPHHPMMTFx4sRoaWmJE088MW655ZaamW/16tWxZcuWmDBhQvTu3Tt69+4dy5cvj1/+8pfRu3fv0izVPudH9evXL8aNGxcbNmyomZ/lkCFD4oQTTuiydvzxx8crr7wSEbXz32RExMsvvxyPP/54XHnllaW1Wpnvpz/9acyaNSsuvPDCGDduXFx66aXxox/9KFpaWiKisnPWTFjsb5d0HzVqVAwePLjLvB988EEsX768quZNKcU111wTDz74YPztb3+LUaNGdbm/Vub8qJRSFIvFmpnvrLPOirVr10ZbW1vpmDhxYlx88cXR1tYWRx11VE3M+VHFYjFeeOGFGDJkSM38LL/yla90+8r3iy++WLrQZK3MGRGxYMGCGDRoUDQ1NZXWamW+9957Lw44oOtf8b169Sp93bSic+7RRz/3MTu/bnrHHXek559/Pk2fPj3169cvbd68eW9vrUe2bt2a1qxZk9asWZMiIt10001pzZo1pa/Pzp8/Pw0YMCA9+OCDae3atemiiy6quq9EXX311WnAgAFp2bJlXb7+9d5775XOqfY5m5ub04oVK9KmTZvSs88+m2bPnp0OOOCA9Nhjj6WUqn++3fnfb4WkVBtz/vjHP07Lli1LGzduTCtXrkzf+ta3Un19fen/Y2phxqeffjr17t07zZs3L23YsCHdc8896eCDD05333136ZxamHP79u1p+PDhaebMmd3uq4X5pkyZkj7/+c+Xvm764IMPpsMPPzz97Gc/K51TqTlrKixSSulXv/pVGjFiROrTp0/60pe+VPraYjV64oknUkR0O6ZMmZJS+u/XhebMmZMGDx6cCoVCOv3009PatWv37qbLtKv5IiItWLCgdE61z3nFFVeU/kweccQR6ayzzipFRUrVP9/ufDQsamHOnd/zP/DAA1NDQ0M6//zz07p160r318KMKaX0pz/9KY0dOzYVCoU0evTodNttt3W5vxbm/Mtf/pIiIq1fv77bfbUwX2dnZ5o2bVoaPnx46tu3bzrqqKPSddddl4rFYumcSs3psukAQDY18xkLAGDvExYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZ/D+FbDNURdei4gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('의무', 5), ('격리', 5), ('코로나', 4), ('방역', 4), ('정부', 3), ('중앙', 3), ('조치', 3), ('대본', 3), ('본부', 3), ('감염병', 3), ('해제', 3), ('대부분', 2), ('재난', 2), ('발생', 2), ('시설', 2), ('대책', 2), ('가능성', 2), ('진자', 2), ('내용', 2), ('감염', 2), ('규제', 2), ('취약', 2), ('개월', 2), ('관리', 2), ('착용', 1), ('완화', 1), ('위기', 1), ('윤석열', 1), ('의견', 1), ('의원', 1), ('이후', 1), ('확산', 1), ('전망', 1), ('하향', 1), ('절차', 1), ('차원', 1), ('조정', 1), ('풍토병', 1), ('주재', 1), ('중수', 1), ('지난', 1), ('예고', 1), ('질병', 1), ('총괄', 1), ('행정', 1), ('엔데믹', 1), ('수습', 1), ('안전', 1), ('개정', 1), ('거론', 1), ('경계', 1), ('경보', 1), ('고시', 1), ('국내', 1), ('권고', 1), ('다만', 1), ('다음', 1), ('단계', 1), ('대통령', 1), ('등급', 1), ('마스크', 1), ('만이', 1), ('발표', 1), ('방안', 1), ('변결', 1), ('병원', 1), ('보건복지부', 1), ('본격', 1), ('사고', 1), ('사실', 1), ('상의', 1), ('선언', 1), ('소요', 1), ('확진', 1), ('시행', 1), ('심각', 1), ('심사', 1), ('약국', 1), ('회의', 1)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "vect = CountVectorizer().fit(txt2)\n",
    "\n",
    "# bow의 출현횟수 합계\n",
    "cnt = vect.transform(txt2).toarray().sum(axis=0)\n",
    "idx = np.argsort(-cnt) # 카운트 내림차순 정렬\n",
    "cnt = cnt[idx]\n",
    "\n",
    "# X축의 단어이름\n",
    "feature_name = np.array(vect.get_feature_names_out())[idx]\n",
    "plt.bar(range(len(cnt)), cnt)\n",
    "plt.show()\n",
    "print(list(zip(feature_name,cnt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2 3 2 1 1 5 1 1 1 2 1 1 2 2 1 1 1 3 2 2 1 1 1 1 2 1 1 4 1 1 1 1 3 1 1\n",
      "  1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 5 1 1 2 1 1 3 1 3 1 1 3 1 2 1 1 1 1 2 4\n",
      "  1 1 3 1 1 1 1]]\n",
      "{'정부': 58, '코로나': 71, '방역': 28, '조치': 60, '대부분': 19, '해제': 74, '사실': 35, '상의': 36, '엔데믹': 46, '풍토병': 72, '감염병': 2, '선언': 37, '국내': 11, '진자': 65, '발생': 25, '개월': 3, '만이': 24, '중앙': 63, '재난': 55, '안전': 44, '대책': 20, '본부': 33, '대본': 18, '윤석열': 50, '대통령': 21, '주재': 61, '회의': 78, '격리': 6, '의무': 52, '내용': 14, '완화': 48, '발표': 26, '확산': 76, '위기': 49, '경보': 8, '단계': 17, '심각': 42, '경계': 7, '하향': 73, '조정': 59, '등급': 22, '의원': 53, '약국': 45, '감염': 1, '취약': 70, '시설': 40, '마스크': 23, '착용': 68, '가능성': 0, '지난': 64, '규제': 13, '관리': 10, '차원': 67, '보건복지부': 31, '사고': 34, '수습': 39, '중수': 62, '질병': 66, '총괄': 69, '변결': 29, '전망': 56, '다만': 15, '병원': 30, '의견': 51, '확진': 77, '이후': 54, '권고': 12, '방안': 27, '거론': 5, '본격': 32, '시행': 41, '다음': 16, '고시': 9, '개정': 4, '행정': 75, '예고': 47, '심사': 43, '절차': 57, '소요': 38}\n"
     ]
    }
   ],
   "source": [
    "#불용어 추가\n",
    "vector = CountVectorizer(stop_words=['더'])\n",
    "print(vector.fit_transform(txt2).toarray())\n",
    "print(vector.vocabulary_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
